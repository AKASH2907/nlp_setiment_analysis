{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "\n",
    "# NLTK Libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "%autosave 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 3)\n",
      "(2553, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Shipment and delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have bought these bags and  immediately open...</td>\n",
       "      <td>TRASH!!! Do not buy these bags it’s a waist of...</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gave me an allergic reaction on my face :(</td>\n",
       "      <td>Do not recommend</td>\n",
       "      <td>Allergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These don't compare to the name brand wipes. F...</td>\n",
       "      <td>Can't tackle big messes</td>\n",
       "      <td>Texture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  Did nothing for me, didn't help lost even with...   \n",
       "1  Did nothing for me, didn't help lost even with...   \n",
       "2  I have bought these bags and  immediately open...   \n",
       "3         Gave me an allergic reaction on my face :(   \n",
       "4  These don't compare to the name brand wipes. F...   \n",
       "\n",
       "                                        Review Title                  topic  \n",
       "0                                            Useless  Shipment and delivery  \n",
       "1                                            Useless          Not Effective  \n",
       "2  TRASH!!! Do not buy these bags it’s a waist of...       Customer Service  \n",
       "3                                   Do not recommend               Allergic  \n",
       "4                            Can't tackle big messes                Texture  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5959</td>\n",
       "      <td>5959</td>\n",
       "      <td>5959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4196</td>\n",
       "      <td>3727</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Their website would have you believe that only...</td>\n",
       "      <td>Gross</td>\n",
       "      <td>Bad Taste/Flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Text Review Title  \\\n",
       "count                                                5959         5959   \n",
       "unique                                               4196         3727   \n",
       "top     Their website would have you believe that only...        Gross   \n",
       "freq                                                    6           19   \n",
       "\n",
       "                   topic  \n",
       "count               5959  \n",
       "unique                21  \n",
       "top     Bad Taste/Flavor  \n",
       "freq                1194  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bad Taste/Flavor           1194\n",
       "Quality/Contaminated        715\n",
       "Not Effective               611\n",
       "Allergic                    567\n",
       "Packaging                   467\n",
       "Texture                     410\n",
       "Shipment and delivery       390\n",
       "Customer Service            239\n",
       "Color and texture           234\n",
       "Too big to swallow          228\n",
       "Ingredients                 216\n",
       "Expiry                      136\n",
       "Smells Bad                  123\n",
       "Pricing                     107\n",
       "Wrong Product received       99\n",
       "Too Sweet                    97\n",
       "Inferior to competitors      44\n",
       "False Advertisement          37\n",
       "Didn't Like                  31\n",
       "Customer Issues               8\n",
       "Hard to Chew                  6\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = train.topic.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shipment and delivery', 'Not Effective', 'Customer Service', 'Allergic', 'Texture', 'Quality/Contaminated', 'Color and texture', 'Bad Taste/Flavor', 'Too big to swallow', 'Smells Bad', 'Too Sweet', 'Ingredients', 'Expiry', 'Packaging', 'Wrong Product received', 'Pricing', 'False Advertisement', 'Inferior to competitors', \"Didn't Like\", 'Customer Issues', 'Hard to Chew']\n"
     ]
    }
   ],
   "source": [
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Shipment and delivery', 1: 'Not Effective', 2: 'Customer Service', 3: 'Allergic', 4: 'Texture', 5: 'Quality/Contaminated', 6: 'Color and texture', 7: 'Bad Taste/Flavor', 8: 'Too big to swallow', 9: 'Smells Bad', 10: 'Too Sweet', 11: 'Ingredients', 12: 'Expiry', 13: 'Packaging', 14: 'Wrong Product received', 15: 'Pricing', 16: 'False Advertisement', 17: 'Inferior to competitors', 18: \"Didn't Like\", 19: 'Customer Issues', 20: 'Hard to Chew'}\n",
      "{'Shipment and delivery': 0, 'Not Effective': 1, 'Customer Service': 2, 'Allergic': 3, 'Texture': 4, 'Quality/Contaminated': 5, 'Color and texture': 6, 'Bad Taste/Flavor': 7, 'Too big to swallow': 8, 'Smells Bad': 9, 'Too Sweet': 10, 'Ingredients': 11, 'Expiry': 12, 'Packaging': 13, 'Wrong Product received': 14, 'Pricing': 15, 'False Advertisement': 16, 'Inferior to competitors': 17, \"Didn't Like\": 18, 'Customer Issues': 19, 'Hard to Chew': 20}\n"
     ]
    }
   ],
   "source": [
    "l = list(range(21))\n",
    "labels = {i : topics[i] for i in range(0, len(topics))}\n",
    "d = dict(zip(topics, l))\n",
    "print(labels)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Shipment and delivery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Not Effective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have bought these bags and  immediately open...</td>\n",
       "      <td>TRASH!!! Do not buy these bags it’s a waist of...</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gave me an allergic reaction on my face :(</td>\n",
       "      <td>Do not recommend</td>\n",
       "      <td>Allergic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These don't compare to the name brand wipes. F...</td>\n",
       "      <td>Can't tackle big messes</td>\n",
       "      <td>Texture</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  Did nothing for me, didn't help lost even with...   \n",
       "1  Did nothing for me, didn't help lost even with...   \n",
       "2  I have bought these bags and  immediately open...   \n",
       "3         Gave me an allergic reaction on my face :(   \n",
       "4  These don't compare to the name brand wipes. F...   \n",
       "\n",
       "                                        Review Title                  topic  \\\n",
       "0                                            Useless  Shipment and delivery   \n",
       "1                                            Useless          Not Effective   \n",
       "2  TRASH!!! Do not buy these bags it’s a waist of...       Customer Service   \n",
       "3                                   Do not recommend               Allergic   \n",
       "4                            Can't tackle big messes                Texture   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       2  \n",
       "3       3  \n",
       "4       4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['labels'] = train[\"topic\"].apply(lambda x: d[x])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8512, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=False)\n",
    "print(all_data.shape)\n",
    "# print(all_data[5965][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8512\n",
      "8512\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "reviews= []\n",
    "\n",
    "for i in all_data['Review Title']:\n",
    "    titles.append(i)\n",
    "\n",
    "for line in all_data['Review Text']:\n",
    "    reviews.append(line)\n",
    "\n",
    "print(len(titles))\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "titles_clean = preprocess_reviews(titles)\n",
    "reviews_clean = preprocess_reviews(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959 2553\n"
     ]
    }
   ],
   "source": [
    "X_train = titles_clean[:train.shape[0]]\n",
    "X_test = titles_clean[train.shape[0]:]\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959\n"
     ]
    }
   ],
   "source": [
    "Y = []\n",
    "\n",
    "for i in train['labels']:\n",
    "    Y+=[i]\n",
    "    \n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 2485)\n",
      "(2553, 2485)\n"
     ]
    }
   ],
   "source": [
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "\n",
    "# Not using stop words\n",
    "\n",
    "v = CountVectorizer()\n",
    "v.fit(X_train)\n",
    "\n",
    "X_train_bow = v.transform(X_train)\n",
    "# X_val_bow = v.transform(X_val)\n",
    "X_test_bow = v.transform(X_test)\n",
    "\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: LR:S:  0.4321194831347542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "c = LogisticRegression(C=0.05)\n",
    "c.fit(X_train_bow, Y)\n",
    "\n",
    "score = c.score(X_train_bow, Y)\n",
    "print(\"Val: LR:S: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553\n"
     ]
    }
   ],
   "source": [
    "test_predict = c.predict(X_test_bow)\n",
    "print(len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2553,)\n"
     ]
    }
   ],
   "source": [
    "print(test_predict.shape)\n",
    "t = test_predict.tolist()\n",
    "# print(t)\n",
    "# new_labels = t.apply(lambda x: labels[x])\n",
    "# print(new_labels)\n",
    "# print(labels.keys())\n",
    "# print(labels.values())\n",
    "final = []\n",
    "for i in t:\n",
    "    final.append(labels[i])\n",
    "#     if i in labels.keys():\n",
    "#         final.append()\n",
    "# print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Review Text': test['Review Text'],\n",
    "    'Review Title':test['Review Title'],\n",
    "    'topic': final\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "      <td>Quality/Contaminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "      <td>Quality/Contaminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t waste your money.</td>\n",
       "      <td>No change. No results.</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "      <td>Quality/Contaminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "      <td>Quality/Contaminated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  I use chia seed in my protein shakes. These ta...   \n",
       "1  I use chia seed in my protein shakes. These ta...   \n",
       "2                            Don’t waste your money.   \n",
       "3  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "4  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "\n",
       "                               Review Title                 topic  \n",
       "0                                  Bad tast  Quality/Contaminated  \n",
       "1                                  Bad tast  Quality/Contaminated  \n",
       "2                    No change. No results.         Not Effective  \n",
       "3  Good Vegan Choice, Poor Non Vegan Choice  Quality/Contaminated  \n",
       "4  Good Vegan Choice, Poor Non Vegan Choice  Quality/Contaminated  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 8509)\n",
      "(2553, 8509)\n"
     ]
    }
   ],
   "source": [
    "X_trainr = reviews_clean[:train.shape[0]]\n",
    "# X_val = justifications_clean[train.shape[0]:train.shape[0]+val.shape[0]]\n",
    "X_testr = reviews_clean[train.shape[0]:]\n",
    "# print(len(X_train), len(X_val), len(X_test))\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "\n",
    "# Not using stop words\n",
    "\n",
    "v = CountVectorizer()\n",
    "v.fit(X_trainr)\n",
    "\n",
    "X_train_bowr = v.transform(X_trainr)\n",
    "# X_val_bow = v.transform(X_val)\n",
    "X_test_bowr = v.transform(X_testr)\n",
    "\n",
    "print(X_train_bowr.shape)\n",
    "print(X_test_bowr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: LR:S:  0.6301392851149522\n",
      "2553\n"
     ]
    }
   ],
   "source": [
    "c = LogisticRegression(C=0.05)\n",
    "c.fit(X_train_bowr, Y)\n",
    "\n",
    "score = c.score(X_train_bowr, Y)\n",
    "print(\"Val: LR:S: \", score)\n",
    "test_predict = c.predict(X_test_bowr)\n",
    "print(len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_predict.tolist()\n",
    "final = []\n",
    "for i in t:\n",
    "    final.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Review Text': test['Review Text'],\n",
    "    'Review Title':test['Review Title'],\n",
    "    'topic': final\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('submit1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8512\n"
     ]
    }
   ],
   "source": [
    "rt_clean = []\n",
    "\n",
    "for i in range(len(titles_clean)):\n",
    "    rt_clean += [titles_clean[i] + SPACE +  reviews_clean[i]]\n",
    "\n",
    "print(len(rt_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959 2553\n"
     ]
    }
   ],
   "source": [
    "X_train = rt_clean[:train.shape[0]]\n",
    "# X_val = s_j_clean[train.shape[0]:train.shape[0]+val.shape[0]]\n",
    "X_test = rt_clean[train.shape[0]:]\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 1000)\n",
      "(2553, 1000)\n"
     ]
    }
   ],
   "source": [
    "# v = CountVectorizer()\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "\n",
    "bow.fit(X_train)\n",
    "\n",
    "X_train_bow = bow.transform(X_train)\n",
    "# X_val_bow = v.transform(X_val)\n",
    "X_test_bow = bow.transform(X_test)\n",
    "\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: LR:S:  0.6554791072327572\n",
      "2553\n"
     ]
    }
   ],
   "source": [
    "c = LogisticRegression(C=0.05)\n",
    "c.fit(X_train_bow, Y)\n",
    "\n",
    "score = c.score(X_train_bow, Y)\n",
    "print(\"Val: LR:S: \", score)\n",
    "test_predict = c.predict(X_test_bow)\n",
    "print(len(test_predict))\n",
    "\n",
    "t = test_predict.tolist()\n",
    "final = []\n",
    "for i in t:\n",
    "    final.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Review Text': test['Review Text'],\n",
    "    'Review Title':test['Review Title'],\n",
    "    'topic': final\n",
    "})\n",
    "\n",
    "# submission.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, Our accuracy Score is: 0.701\n"
     ]
    }
   ],
   "source": [
    "# import LogisticRegression model in python. \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "## call on the model object\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "## fit the model with \"train_x\" and \"train_y\"\n",
    "logreg.fit(X_train_bow,Y)\n",
    "\n",
    "## Once the model is trained we want to find out how well the model is performing, so we test the model. \n",
    "## we use \"test_x\" portion of the data(this data was not used to fit the model) to predict model outcome. \n",
    "y_pred = logreg.predict(X_test_bow)\n",
    "y = logreg.predict(X_train_bow)\n",
    "## Once predicted we save that outcome in \"y_pred\" variable.\n",
    "## Then we compare the predicted value( \"y_pred\") and actual value(\"test_y\") to see how well our model is performing. \n",
    "\n",
    "print (\"So, Our accuracy Score is: {}\".format(round(accuracy_score(y, Y),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "final = []\n",
    "for i in t:\n",
    "    final.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Review Text': test['Review Text'],\n",
    "    'Review Title':test['Review Title'],\n",
    "    'topic': final\n",
    "})\n",
    "\n",
    "submission.to_csv('submit4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=None, test_size=0.25,\n",
       "            train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3,\n",
       "                               4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 16.5,\n",
       "                               17, 17.5, 18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "## C_vals is the alpla value of lasso and ridge regression(as alpha increases the model complexity decreases,)\n",
    "## remember effective alpha scores are 0<alpha<infinity \n",
    "C_vals = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,16.5,17,17.5,18]\n",
    "\n",
    "## Choosing penalties(Lasso(l1) or Ridge(l2))\n",
    "penalties = ['l1','l2']\n",
    "## Choose a cross validation strategy. \n",
    "cv = StratifiedShuffleSplit(n_splits = 5, test_size = .25)\n",
    "\n",
    "## setting param for param_grid in GridSearchCV. \n",
    "# param = {'penalty': penalties, 'C': C_vals}\n",
    "param = {'C': C_vals}\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "## Calling on GridSearchCV object. \n",
    "grid = GridSearchCV(estimator=LogisticRegression(), \n",
    "                           param_grid = param,\n",
    "                           scoring = 'accuracy',\n",
    "                            n_jobs =-1,\n",
    "                           cv = cv\n",
    "                          )\n",
    "## Fitting the model\n",
    "grid.fit(X_train_bow, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5005369127516779\n",
      "{'C': 0.2}\n",
      "LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "## Getting the best of everything. \n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856855177043129"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_grid = grid.best_estimator_\n",
    "logreg_grid.score(X_train_bow,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation accuracy scores:[0.32348993 0.33758389 0.34697987 0.34563758 0.33221477 0.3557047\n",
      " 0.33355705 0.35167785 0.3590604  0.35100671]\n",
      "Mean Cross-Validation accuracy score: 0.344\n"
     ]
    }
   ],
   "source": [
    "# kNN with GridSearch CV\n",
    "## Importing the model. \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## calling on the model oject. \n",
    "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
    "## knn classifier works by doing euclidian distance \n",
    "\n",
    "\n",
    "## doing 10 fold staratified-shuffle-split cross validation \n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.25, random_state=2)\n",
    "\n",
    "accuracies = cross_val_score(knn, X_train_bow,Y, cv = cv, scoring='accuracy')\n",
    "print (\"Cross-Validation accuracy scores:{}\".format(accuracies))\n",
    "print (\"Mean Cross-Validation accuracy score: {}\".format(round(accuracies.mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores are: [0.25724832214765103, 0.27818791946308724, 0.3093959731543624, 0.32932885906040266, 0.3436912751677852, 0.35583892617449664, 0.35946308724832216, 0.363758389261745, 0.36979865771812076, 0.3710067114093959, 0.3704697986577181, 0.376510067114094, 0.37852348993288587, 0.37926174496644294, 0.37993288590604024, 0.37932885906040265, 0.380738255033557, 0.38120805369127525, 0.38093959731543625, 0.3822147651006712, 0.3818791946308725, 0.38167785234899326, 0.38140939597315443, 0.3824832214765101, 0.38288590604026845, 0.3808724832214765, 0.38060402684563754, 0.3805369127516779, 0.3789261744966443, 0.37751677852348997]\n",
      "\n",
      "Mean accuracy score: 0.3645212527964205\n"
     ]
    }
   ],
   "source": [
    "## Search for an optimal value of k for KNN. MANUAL\n",
    "k_range = range(1,31)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_bow,Y, cv = cv, scoring = 'accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(\"Accuracy scores are: {}\\n\".format(k_scores))\n",
    "print (\"Mean accuracy score: {}\".format(np.mean(k_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=15, test_size=0.3,\n",
       "            train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(1, 31),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbours Classifier with gridSearch CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "## trying out multiple values for k\n",
    "k_range = range(1,31)\n",
    "## \n",
    "weights_options=['uniform','distance']\n",
    "# \n",
    "param = {'n_neighbors':k_range, 'weights':weights_options}\n",
    "## Using startifiedShufflesplit. \n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\n",
    "# estimator = knn, param_grid = param, n_jobs = -1 to instruct scikit learn to use all available processors. \n",
    "grid = GridSearchCV(KNeighborsClassifier(), param,cv=cv,verbose = False, n_jobs=-1)\n",
    "## Fitting the model. \n",
    "grid.fit(X_train_bow,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3851230425055928\n",
      "{'n_neighbors': 25, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4494042624601443"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid= grid.best_estimator_\n",
    "knn_grid.score(X_train_bow,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_bow\n",
    "y =Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "Cs = [0.001, 0.01, 0.1, 1,1.5,2,2.5,3,4,5, 10] ## penalty parameter C for the error term. \n",
    "gammas = [0.0001,0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\n",
    "grid_search = GridSearchCV(SVC(kernel = 'rbf', probability=True), param_grid, cv=cv) ## 'rbf' stands for gaussian kernel\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid = grid_search.best_estimator_\n",
    "svm_grid.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.sklearn import XGBClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n",
    "#                                 max_depth=4, min_child_weight=0,\n",
    "#                                 gamma=0, subsample=0.7,\n",
    "#                                 colsample_bytree=0.7,\n",
    "#                                 scale_pos_weight=1, seed=27,\n",
    "#                                 reg_alpha=0.00006)\n",
    "# model.fit(X_train_bow, Y)\n",
    "# score = model.score(X_train_bow, Y)\n",
    "# print(\"Val: LR:S: \", score)\n",
    "# test_predict = model.predict(X_test_bow)\n",
    "# print(len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "max_depth = range(1,30)\n",
    "max_feature = [21,22,23,24,25,26,28,29,30,'auto']\n",
    "criterion=[\"entropy\", \"gini\"]\n",
    "\n",
    "param = {'max_depth':max_depth, \n",
    "         'max_features':max_feature, \n",
    "         'criterion': criterion}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), \n",
    "                                param_grid = param, \n",
    "                                 verbose=False, \n",
    "                                 cv=StratifiedKFold(n_splits=20, random_state=15, shuffle=True),\n",
    "                                n_jobs = -1)\n",
    "grid.fit(X, y) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
