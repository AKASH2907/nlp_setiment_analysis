{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import string\n",
    "import inflect\n",
    "# from contractions import contractions_dict\n",
    "\n",
    "# NLTK Libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tyrion/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tyrion/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "all_data = pd.concat([train, test], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8512\n",
      "8512\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "reviews= []\n",
    "\n",
    "for i in all_data['Review Title']:\n",
    "    titles.append(i)\n",
    "\n",
    "for line in all_data['Review Text']:\n",
    "    reviews.append(line)\n",
    "\n",
    "print(len(titles))\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lowercase(text): \n",
    "    return text.lower()\n",
    "\n",
    "def remove_numbers(text): \n",
    "    result = re.sub(r'\\d+', '', text) \n",
    "    return result \n",
    "\n",
    "p = inflect.engine() \n",
    "  \n",
    "# convert number into words \n",
    "def convert_number(text): \n",
    "    # split string into list of words \n",
    "    temp_str = text.split() \n",
    "    # initialise empty list \n",
    "    new_string = [] \n",
    "  \n",
    "    for word in temp_str: \n",
    "        # if word is a digit, convert the digit \n",
    "        # to numbers and append into the new_string list \n",
    "        if word.isdigit(): \n",
    "            temp = p.number_to_words(word) \n",
    "            new_string.append(temp) \n",
    "  \n",
    "        # append the word as it is \n",
    "        else: \n",
    "            new_string.append(word) \n",
    "  \n",
    "    # join the words of new_string to form a string \n",
    "    temp_str = ' '.join(new_string) \n",
    "    return temp_str \n",
    "\n",
    "def remove_punctuation(text): \n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_whitespace(text): \n",
    "    return  \" \".join(text.split()) \n",
    "\n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() \n",
    "  \n",
    "# stem words in the list of tokenised words \n",
    "def stem_words(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    return stems \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "# lemmatize string \n",
    "def lemmatize_word(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    # provide context i.e. part-of-speech \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return lemmas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in reviews[:5]:\n",
    "#     sentence = text_lowercase(sentence)\n",
    "# #     sentence = remove_numbers(sentence)\n",
    "#     sentence = convert_number(sentence)\n",
    "#     sentence = remove_punctuation(sentence)\n",
    "#     sentence = remove_whitespace(sentence)\n",
    "#     sentence = remove_stopwords(sentence)\n",
    "# #     sentence = stem_words(sentence)\n",
    "# #     sentence = lemmatize\n",
    "    \n",
    "#     print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did nothing for me, didn't help lost even with...\n",
       "1    did nothing for me, didn't help lost even with...\n",
       "2    i have bought these bags and immediately open ...\n",
       "3           gave me an allergic reaction on my face :(\n",
       "4    these don't compare to the name brand wipes. f...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lower\n",
    "all_data['Review Text'] = all_data['Review Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "all_data['Review Text'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did nothing for me didnt help lost even with w...\n",
       "1    did nothing for me didnt help lost even with w...\n",
       "2    i have bought these bags and immediately open ...\n",
       "3             gave me an allergic reaction on my face \n",
       "4    these dont compare to the name brand wipes fam...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation\n",
    "all_data['Review Text'] = all_data['Review Text'].str.replace('[^\\w\\s]','')\n",
    "all_data['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nothing didnt help lost even working eating he...\n",
       "1    nothing didnt help lost even working eating he...\n",
       "2    bought bags immediately open one put trash bag...\n",
       "3                          gave allergic reaction face\n",
       "4    dont compare name brand wipes family 5 little ...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords\n",
    "stop = stopwords.words('english')\n",
    "all_data['Review Text'] = all_data['Review Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "all_data['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like       2710\n",
       "product    2518\n",
       "taste      2377\n",
       "brand      1716\n",
       "one        1573\n",
       "flavor     1534\n",
       "bad        1499\n",
       "dont       1322\n",
       "get        1313\n",
       "good       1308\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(all_data['Review Text']).split()).value_counts()[:10]\n",
    "freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = list(freq.index)\n",
    "# all_data['Review Text'] = all_data['Review Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "# all_data['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heartburnbr                               1\n",
       "policies                                  1\n",
       "thicksmall                                1\n",
       "mgbr                                      1\n",
       "enhancement                               1\n",
       "chili                                     1\n",
       "closure                                   1\n",
       "pas                                       1\n",
       "trod                                      1\n",
       "nada                                      1\n",
       "promotes                                  1\n",
       "providers                                 1\n",
       "overpacking                               1\n",
       "faints                                    1\n",
       "lefthalf                                  1\n",
       "fitmiss                                   1\n",
       "ithence                                   1\n",
       "bruising                                  1\n",
       "gelbut                                    1\n",
       "primeprime                                1\n",
       "graden                                    1\n",
       "exploding                                 1\n",
       "counselor                                 1\n",
       "protocol                                  1\n",
       "triggered                                 1\n",
       "digestively                               1\n",
       "vain                                      1\n",
       "cracks                                    1\n",
       "cheat                                     1\n",
       "videoid55ee6c1b5b9397d601cf232751911d4    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(all_data['Review Text']).split()).value_counts()[-30:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nothing didnt help lost even working eating he...\n",
       "1    nothing didnt help lost even working eating he...\n",
       "2    bought bags immediately open one put trash bag...\n",
       "3                          gave allergic reaction face\n",
       "4    dont compare name brand wipes family 5 little ...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "all_data['Review Text'] = all_data['Review Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "all_data['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# all_data['Review Text'].apply(lambda x: str(TextBlob(x).correct()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       noth didnt help lost even work eat healthi did...\n",
       "1       noth didnt help lost even work eat healthi did...\n",
       "2       bought bag immedi open one put trash bag split...\n",
       "3                               gave allerg reaction face\n",
       "4       dont compar name brand wipe famili 5 littl kid...\n",
       "5       dont compar name brand wipe famili 5 littl kid...\n",
       "6       dont compar name brand wipe famili 5 littl kid...\n",
       "7                                                    good\n",
       "8       extrem hard swallow pill huge side sharp serio...\n",
       "9       first style leav review solimo incontin maximu...\n",
       "10      first style leav review solimo incontin maximu...\n",
       "11      first style leav review solimo incontin maximu...\n",
       "12      smell horribl soon open bottl hit smell ammoni...\n",
       "13      super easi dont work definit doesnt give energ...\n",
       "14      super easi dont work definit doesnt give energ...\n",
       "15      light big disappoint find good veggi vitamin i...\n",
       "16      light big disappoint find good veggi vitamin i...\n",
       "17                   absolut improv health way shape form\n",
       "18      neck surgeri thought would stock last order bi...\n",
       "19      dont know rate high use mani differ brand lave...\n",
       "20      dont know rate high use mani differ brand lave...\n",
       "21      dont know rate high use mani differ brand lave...\n",
       "22      doesnt smell anyth like rosehip oil smell like...\n",
       "23      doesnt smell anyth like rosehip oil smell like...\n",
       "24       thought use size need 39 gallon find use one bad\n",
       "25      tast aw cut swallow piec tri get without tast ...\n",
       "26      realli like diaper ive never problem time ive ...\n",
       "27      idea got great review liter pass 2 week though...\n",
       "28      order rip version got regular order raspberri ...\n",
       "29      love diaper longer buy price gone 12 less two ...\n",
       "                              ...                        \n",
       "2523    review said smell bad think oh probabl smell l...\n",
       "2524    review said smell bad think oh probabl smell l...\n",
       "2525    bought august 2018 bare use first bought went ...\n",
       "2526    bought daughter think would help calm stress h...\n",
       "2527    bought daughter think would help calm stress h...\n",
       "2528    bought im anem late pregnanc hate swallow vita...\n",
       "2529    would give zero could never even receiv damag ...\n",
       "2530    would give zero could never even receiv damag ...\n",
       "2531    ive purchas kirkland oliv oil past gener good ...\n",
       "2532    wild cherri flavor enjoy albeit sweet tast im ...\n",
       "2533    wild cherri flavor enjoy albeit sweet tast im ...\n",
       "2534    wild cherri flavor enjoy albeit sweet tast im ...\n",
       "2535    wild cherri flavor enjoy albeit sweet tast im ...\n",
       "2536    2nd use woke middl night w sever stomach cramp...\n",
       "2537    2nd use woke middl night w sever stomach cramp...\n",
       "2538                                       big time overr\n",
       "2539    collagen unflavor tast palat howev mix well li...\n",
       "2540    wish read review product purchas agre comment ...\n",
       "2541    wish read review product purchas agre comment ...\n",
       "2542                                              rubbish\n",
       "2543    tri half scoop mix water within hour heart rat...\n",
       "2544    stir easili dissolv clumpi gooey also strong t...\n",
       "2545    bag one roll miss cut whole side bag blown 5 b...\n",
       "2546    product burst open box creat mess room residu ...\n",
       "2547    wors protein ive ever tri tast horribl sweet d...\n",
       "2548    wors protein ive ever tri tast horribl sweet d...\n",
       "2549    small easi swallow flavor left stomach knotsho...\n",
       "2550    small easi swallow flavor left stomach knotsho...\n",
       "2551       good increas bad cholesterol ldlbr doesnt suit\n",
       "2552                                           buy powder\n",
       "Name: Review Text, Length: 8512, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = PorterStemmer()\n",
    "all_data['Review Text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nothing didnt help lost even working eating he...\n",
       "1    nothing didnt help lost even working eating he...\n",
       "2    bought bag immediately open one put trash bag ...\n",
       "3                          gave allergic reaction face\n",
       "4    dont compare name brand wipe family 5 little k...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "all_data['Review Text'] = all_data['Review Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "all_data['Review Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing didnt help lost even working eating he...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Shipment and delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothing didnt help lost even working eating he...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought bag immediately open one put trash bag ...</td>\n",
       "      <td>TRASH!!! Do not buy these bags it’s a waist of...</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gave allergic reaction face</td>\n",
       "      <td>Do not recommend</td>\n",
       "      <td>Allergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont compare name brand wipe family 5 little k...</td>\n",
       "      <td>Can't tackle big messes</td>\n",
       "      <td>Texture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  nothing didnt help lost even working eating he...   \n",
       "1  nothing didnt help lost even working eating he...   \n",
       "2  bought bag immediately open one put trash bag ...   \n",
       "3                        gave allergic reaction face   \n",
       "4  dont compare name brand wipe family 5 little k...   \n",
       "\n",
       "                                        Review Title                  topic  \n",
       "0                                            Useless  Shipment and delivery  \n",
       "1                                            Useless          Not Effective  \n",
       "2  TRASH!!! Do not buy these bags it’s a waist of...       Customer Service  \n",
       "3                                   Do not recommend               Allergic  \n",
       "4                            Can't tackle big messes                Texture  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959 2553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    nothing didnt help lost even working eating he...\n",
       "1    nothing didnt help lost even working eating he...\n",
       "2    bought bag immediately open one put trash bag ...\n",
       "3                          gave allergic reaction face\n",
       "4    dont compare name brand wipe family 5 little k...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = all_data['Review Text'][:train.shape[0]]\n",
    "X_test = all_data['Review Text'][train.shape[0]:]\n",
    "print(len(X_train), len(X_test))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    use chia seed protein shake tasted like moldy ...\n",
       "1    use chia seed protein shake tasted like moldy ...\n",
       "2                                     dont waste money\n",
       "3    use book fortify life tieraona low dog md help...\n",
       "4    use book fortify life tieraona low dog md help...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 3000)\n",
      "(2553, 3000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "# bow = CountVectorizer()\n",
    "# train_bow = \n",
    "bow.fit(X_train)\n",
    "\n",
    "X_train_bow = bow.transform(X_train)\n",
    "# X_val_bow = v.transform(X_val)\n",
    "X_test_bow = bow.transform(X_test)\n",
    "\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Shipment and delivery', 1: 'Not Effective', 2: 'Customer Service', 3: 'Allergic', 4: 'Texture', 5: 'Quality/Contaminated', 6: 'Color and texture', 7: 'Bad Taste/Flavor', 8: 'Too big to swallow', 9: 'Smells Bad', 10: 'Too Sweet', 11: 'Ingredients', 12: 'Expiry', 13: 'Packaging', 14: 'Wrong Product received', 15: 'Pricing', 16: 'False Advertisement', 17: 'Inferior to competitors', 18: \"Didn't Like\", 19: 'Customer Issues', 20: 'Hard to Chew'}\n",
      "{'Shipment and delivery': 0, 'Not Effective': 1, 'Customer Service': 2, 'Allergic': 3, 'Texture': 4, 'Quality/Contaminated': 5, 'Color and texture': 6, 'Bad Taste/Flavor': 7, 'Too big to swallow': 8, 'Smells Bad': 9, 'Too Sweet': 10, 'Ingredients': 11, 'Expiry': 12, 'Packaging': 13, 'Wrong Product received': 14, 'Pricing': 15, 'False Advertisement': 16, 'Inferior to competitors': 17, \"Didn't Like\": 18, 'Customer Issues': 19, 'Hard to Chew': 20}\n"
     ]
    }
   ],
   "source": [
    "topics = train.topic.unique().tolist()\n",
    "\n",
    "l = list(range(21))\n",
    "labels = {i : topics[i] for i in range(0, len(topics))}\n",
    "d = dict(zip(topics, l))\n",
    "# print(labels)\n",
    "# print(d)\n",
    "train['labels'] = train[\"topic\"].apply(lambda x: d[x])\n",
    "\n",
    "\n",
    "Y = []\n",
    "\n",
    "for i in train['labels']:\n",
    "    Y+=[i]\n",
    "    \n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: LR:S:  0.6064775969122336\n",
      "2553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c = LogisticRegression(C=0.05)\n",
    "c.fit(X_train_bow, Y)\n",
    "\n",
    "score = c.score(X_train_bow, Y)\n",
    "print(\"Val: LR:S: \", score)\n",
    "test_predict = c.predict(X_test_bow)\n",
    "print(len(test_predict))\n",
    "\n",
    "t = test_predict.tolist()\n",
    "final = []\n",
    "for i in t:\n",
    "    final.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Review Text': test['Review Text'],\n",
    "    'Review Title':test['Review Title'],\n",
    "    'topic': final\n",
    "})\n",
    "\n",
    "# submission.to_csv('submit4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LogisticRegression model in python. \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "## call on the model object\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "## fit the model with \"train_x\" and \"train_y\"\n",
    "logreg.fit(X_train_bow,Y)\n",
    "\n",
    "## Once the model is trained we want to find out how well the model is performing, so we test the model. \n",
    "## we use \"test_x\" portion of the data(this data was not used to fit the model) to predict model outcome. \n",
    "y_pred = logreg.predict(X_test_bow)\n",
    "y = logreg.predict(X_train_bow)\n",
    "## Once predicted we save that outcome in \"y_pred\" variable.\n",
    "## Then we compare the predicted value( \"y_pred\") and actual value(\"test_y\") to see how well our model is performing. \n",
    "\n",
    "print (\"So, Our accuracy Score is: {}\".format(round(accuracy_score(y, Y),4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
